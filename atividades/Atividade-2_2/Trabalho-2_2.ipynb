{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a861aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q numpy\n",
    "%pip install -q scipy\n",
    "%pip install -q matplotlib\n",
    "%pip install -q scikit-learn\n",
    "%pip install -q pandas\n",
    "%pip install -q statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26060690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6017e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd\n",
    "\n",
    "CWD: str = getcwd()\n",
    "ASSETS_DIR: str = CWD + \"/Assets-2_2\"\n",
    "DATASET_DIR: str = ASSETS_DIR + \"/heightWeight.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324a33b",
   "metadata": {},
   "source": [
    "# Questão A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function(x: ndarray) -> ndarray:\n",
    "    return x * 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1156a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_distribution(x: ndarray) -> ndarray:\n",
    "    return np.random.uniform(size=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4194407",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_POINTS: ndarray = np.linspace(0, 1, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax1, ax2 = axes\n",
    "\n",
    "# ---- Linear function ----\n",
    "y1: ndarray = linear_function(X_POINTS)\n",
    "ax1.scatter(X_POINTS, y1)\n",
    "\n",
    "# get the linear regression\n",
    "slope1, intercept1, r_value1, p_value1, std_err1 = stats.linregress(X_POINTS, y1)\n",
    "line1: ndarray = slope1 * X_POINTS + intercept1\n",
    "ax1.plot(X_POINTS, line1, label=\"Linear regression\", linestyle=\"--\")\n",
    "\n",
    "# ---- Uniform distribution ----\n",
    "y2: ndarray = uniform_distribution(X_POINTS)\n",
    "ax2.scatter(X_POINTS, y2)\n",
    "\n",
    "# get the linear regression\n",
    "slope2, intercept2, r_value2, p_value2, std_err2 = stats.linregress(X_POINTS, y2)\n",
    "line2: ndarray = slope2 * X_POINTS + intercept2\n",
    "ax2.plot(X_POINTS, line2, label=\"Linear regression\", linestyle=\"--\")\n",
    "\n",
    "ax1.set_title(\"Linear function\")\n",
    "ax2.set_title(\"Uniform Distribution\")\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc9f40",
   "metadata": {},
   "source": [
    "# Questão B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53b4bb8",
   "metadata": {},
   "source": [
    "## Valores para a visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39630bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BINS: int = 40\n",
    "DENSITY: bool = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb94132",
   "metadata": {},
   "source": [
    "## Carregando o dataset de pesos e alturas do [Kaggle](https://www.kaggle.com/datasets/burnoutminer/heights-and-weights-dataset?resource=download)\n",
    "\n",
    "Esse dataset contém o total de 25 mil amostras de diferentes humanos de 18 anos de idades. Suas colunas são `Height(Inches)` em polegadas (_inches_) e `Weight(Pounds)` em libras (_pounds_). Utilizaremos apenas a coluna de altura (`Height(Inches)`) em passaremos ela para centímetros para melhorar a visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df: DataFrame = pd.read_csv(DATASET_DIR)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304b8bf",
   "metadata": {},
   "source": [
    "## Manipulação dos dados\n",
    "\n",
    "Iremos transformar a coluna `Height(Inches)` em valores mais comuns para o brasileiro, então converteremos os valores para centímetros e iremos trocar o nome da coluna.\n",
    "\n",
    "Para conversão, basta multiplicar a quantidade de polegadas vezes 2.54. Também converteremos a coluna de `weight` para que ela esteja convertida para quilogramas, basta \n",
    "multiplicar cada amostra por 0.453592."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT_COLUMN: str = \"height\"\n",
    "WEIGHT_COLUMN: str = \"weight\"\n",
    "\n",
    "# create a copy, rename the Height(Inches) to height, return just the height column\n",
    "df_cleaned: DataFrame = df.copy().rename(columns={\"Height(Inches)\":HEIGHT_COLUMN, \"Weight(Pounds)\":WEIGHT_COLUMN}).drop(columns=[\"Index\"])\n",
    "\n",
    "# convert to cm\n",
    "df_cleaned[HEIGHT_COLUMN] = df_cleaned[HEIGHT_COLUMN].map(lambda x: x*2.54)\n",
    "\n",
    "# convert to kg\n",
    "df_cleaned[WEIGHT_COLUMN] = df_cleaned[WEIGHT_COLUMN].map(lambda x: x*0.453592)\n",
    "\n",
    "display(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c57a36",
   "metadata": {},
   "source": [
    "## Análise da altura\n",
    "\n",
    "Calculamos a média e o desvio padrão para conseguirmos encontrar o intervalo de confiança da distribuição normal. Para buscar esse intervalo \n",
    "utilizamos o `scipy.stats.norm.interval` para pegarmos exatamente o intervalo que desejamos.\n",
    "\n",
    "A formula usada é:\n",
    "\n",
    "$$\n",
    "\\text{CI} = \\bar{x} \\pm z \\times \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "- $z$ - Nível de confiança\n",
    "- $\\bar{x}$ - Média da amostra\n",
    "- $\\sigma$ - Desvio padrão da amostra\n",
    "- $n$ - Tamanho da amostra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490251ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean: float = df_cleaned[HEIGHT_COLUMN].mean()\n",
    "std: float = df_cleaned[HEIGHT_COLUMN].std() # type: ignore\n",
    "\n",
    "confidences: tuple[float, ...] = (0.85, 0.9, 0.95, 0.99)\n",
    "results: dict[float, tuple] = {}\n",
    "\n",
    "for confidence in confidences:\n",
    "    interval: tuple = stats.norm.interval(confidence, loc=mean, scale=std)\n",
    "    print(f\"Para uma confiança de {int(confidence * 100)}%, temos o intervalo: [{interval[0]}, {interval[1]}]\")\n",
    "    results[confidence] = interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0852848d",
   "metadata": {},
   "source": [
    "## Criando o histograma para mostrar graficamente a distribuição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d5ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors: tuple[str, str, str, str] = ('#66b3ff', '#3399ff', '#0066cc', '#0044cc')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# histogram\n",
    "plt.hist(df_cleaned[HEIGHT_COLUMN], density=DENSITY, bins=BINS, alpha=0.3, color='grey', label=\"Dados (Amostra)\")\n",
    "\n",
    "# mean line\n",
    "plt.axvline(mean, color=\"red\", linestyle=\"--\", label=f\"Média: {mean:.5f}\")\n",
    "\n",
    "# confidence bar\n",
    "y_max: float = plt.gca().get_ylim()[1] # graphic top\n",
    "confidence_heights: tuple[float, float, float, float] = (y_max*0.1, y_max*0.2, y_max*0.3, y_max*0.4)\n",
    "\n",
    "for i, (confidence, interval) in enumerate(results.items()):\n",
    "    erro = (interval[1] - interval[0]) / 2\n",
    "\n",
    "    plt.errorbar(mean, confidence_heights[i], xerr=erro, fmt=\"o\", capsize=8, color=colors[i], label=f\"Intervalo de Confiança: {int(confidence*100)}%\")\n",
    "\n",
    "plt.ylim(0, y_max * 1.2) # increase the graphic height\n",
    "plt.title(\"Distribuição da Altura e Intervalo de Confiança\")\n",
    "plt.xlabel(\"Altura (cm)\")\n",
    "plt.ylabel(\"Densidade (número de amostras no bin)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5ca97a",
   "metadata": {},
   "source": [
    "# Questão C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bacd20",
   "metadata": {},
   "source": [
    "## Definindo a quantidade de amostras para cada grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76053a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_NUMBER: int = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c6bb8",
   "metadata": {},
   "source": [
    "## Criando os grupos com base no dataset da questão anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c496df",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = np.random.default_rng()\n",
    "\n",
    "# get a random sample of values to control group\n",
    "control = df_cleaned[HEIGHT_COLUMN].sample(SAMPLES_NUMBER, random_state=generator)\n",
    "\n",
    "# get a random sample of values to test group\n",
    "test = df_cleaned[HEIGHT_COLUMN].sample(SAMPLES_NUMBER, random_state=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d7d44",
   "metadata": {},
   "source": [
    "## Utilizando `scipy.stats.ttest_ind` para verificar o p_value e o t_stat, ambos provindos da fórmula estatística da distribuição T-Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15362a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value = stats.ttest_ind(control, test)\n",
    "\n",
    "print(f\"Média Controle: {control.mean()}\")\n",
    "print(f\"Média Teste: {test.mean()}\")\n",
    "print(f\"Estatística T: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de01dc",
   "metadata": {},
   "source": [
    "## Avaliação do p_value\n",
    "\n",
    "Se o valor de p_value for menor que um dado $\\alpha$ qualquer no intervalo $[0, 1]$, então a nossa hipótese nula está correta. Quantos mais valores aleatórios forem buscados, menor \n",
    "será o t_stat, o qual representa a diferença entre o grupo controle e o grupo de teste. Isso significa que mais dados dão uma confiança muito maior para os nossos resultados. Dado essa\n",
    "explicação, decidi utilizar um valor de $\\alpha$ igual a 0.05, para que o `p_value` seja menor que ele, ou seja, uma confiança maior que 95%.\n",
    "\n",
    "Logo, a Hipótese Nula ($H_0$) é de que os dados que pegamos não são distintos. E a Hipótese Alternativa ($H_1$) é de que os dados são estatisticamente diferentes entre os grupos, ou \n",
    "seja, são diferentes comuns.\n",
    "\n",
    "- $H_0$ - Os grupos são estatisticamente iguais\n",
    "- $H_1$ - Os grupos são estatisticamente diferentes\n",
    "\n",
    "Em outras palavras, o $\\alpha$ é um valor de confiança que aceitamos tolerar. Caso seja um $\\alpha$ muito grande, então a chance de ser por a caso é maior e, por isso, o resultado não\n",
    "é considerado confiável. Desse modo, o `p_value` reflete a chance de termos conseguido esse resultado por a caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a29af",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha: float = 0.05\n",
    "\n",
    "if p_value < alpha: # type: ignore\n",
    "    print(f\"Decisão: Hipótese nula rejeitada. O p-value é suficientemente confiável: {p_value}\")\n",
    "    print(f\"Conclusão: Existe uma diferença estatisticamente significativa entre os grupos\")\n",
    "else:\n",
    "    print(f\"Decisão: Hipótese nula aceita. O p-value não é suficientemente confiável: {p_value}\")\n",
    "    print(f\"Conclusão: Existe uma diferença estatisticamente pequena entre os grupos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0937ed",
   "metadata": {},
   "source": [
    "# Questão D\n",
    "\n",
    "O slide pode ser encontrado no [link](https://docs.google.com/presentation/d/18qr6W9VnDn1slNsL1n7vQRvynUyGTF1Agm1K0FSbRpo/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2671d13c",
   "metadata": {},
   "source": [
    "# Questão E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d7ef2d",
   "metadata": {},
   "source": [
    "## Calculando o valor de $t$ crítico para utilizar com a distribuição _t-student_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bd11ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "confidence_level: float = 0.975\n",
    "degrees_of_freedon: int = 49\n",
    "\n",
    "t_critical: ndarray = t.ppf(confidence_level, degrees_of_freedon)\n",
    "print(t_critical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ba1cb7",
   "metadata": {},
   "source": [
    "## Calculando o intervalo de confiança com base da fórmula\n",
    "\n",
    "$$\n",
    "\\bar{x} \\pm t^* \\cdot \\frac{s}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "- $\\bar{x}$ - Média dos dados coletados\n",
    "- $t^*$ - Valor dado pela distribuição _t-student_\n",
    "- $s$ - Desvio padrão das amostras\n",
    "- $n$ - Número de amostras\n",
    "\n",
    "Por meio dessa fórmula é possível identificar qual é a chance o intervalo de confiança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45aac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean: float = 75.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f92b82",
   "metadata": {},
   "source": [
    "# Questão F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0421d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1c16f",
   "metadata": {},
   "source": [
    "## Pegando os valores dos pontos originais do gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f870046",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE: float = 0.4\n",
    "X: ndarray = np.array((1.0, 1.8, 2.4, 3.0, 3.5, 4.2, 4.8, 5.5, 6.1)).reshape(-1, 1)\n",
    "\n",
    "def linear_function_with_noise(x: ndarray, a: float = 0.78, b: float = 0.1) -> ndarray:\n",
    "    return (a*x + b).flatten() + np.random.normal(0,NOISE, size=len(x))\n",
    "\n",
    "y: ndarray = linear_function_with_noise(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea40498",
   "metadata": {},
   "source": [
    "## Usando a regressão linear do scikit-learn\n",
    "\n",
    "A regressão linear do scikit-learn irá encontrar o melhor \"a\" (`a_optimo`) e o melhor \"b\" (`b_optimo`), além de calcular o menor SEQ (Soma do erro quadrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "model: LinearRegression = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "b_optimo = model.intercept_\n",
    "a_optimo = model.coef_[0]\n",
    "y_pred_opt = model.predict(X)\n",
    "r2_optimo = r2_score(y, y_pred_opt)\n",
    "\n",
    "header: str = \"---- Melhores parâmetros encontrados pelo Scikit-learn ----\"\n",
    "print(header)\n",
    "print(f\"Intercepto (b): {b_optimo}\")\n",
    "print(f\"Inclinação (a): {a_optimo}\")\n",
    "print(f\"R-Squared: {r2_optimo}\")\n",
    "print(\"-\" * len(header))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f1efd1",
   "metadata": {},
   "source": [
    "## Utilizando o Statsmodels para conseguir as estatísticas gerais\n",
    "\n",
    "Ele realizará o mesmo processo que o scikit-learn, porém coleta mais dados para serem analisados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2826bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm = sm.add_constant(X)\n",
    "model_sm = sm.OLS(y, X_sm).fit()\n",
    "print(model_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d8de2",
   "metadata": {},
   "source": [
    "## Definindo as variáveis para guardas o pontos que serão testados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9aa65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOPE_DIFF: float = 0.5\n",
    "SLOPES_TO_TEST: int = 6\n",
    "slopes_to_test = np.linspace(a_optimo - SLOPE_DIFF, a_optimo + SLOPE_DIFF, SLOPES_TO_TEST)\n",
    "\n",
    "ssr_values = []\n",
    "r2_values = []\n",
    "slopes_all = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fbcd68",
   "metadata": {},
   "source": [
    "## Gerando gráficos\n",
    "\n",
    "### Gerando o gráfico 1\n",
    "\n",
    "O gráfico 1 será o gráfico mostrando a reta em si, lá estará a regressão linear e outros 5 a's para serem comparados\n",
    "\n",
    "### Gerando o gráfico 2\n",
    "\n",
    "O gráfico 2 é responsável por mostrar a soma do erro quadrado para demonstrar o qual próximo a reta está do resultado ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea3ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ---- Graph 1 ----\n",
    "# a's tests\n",
    "ax1.scatter(X, y, color='red', s=100, label='Dados Reais', edgecolor='black')\n",
    "ax1.plot(X, y_pred_opt, color='black', linewidth=3, label=f'Melhor Ajuste (a={a_optimo})')\n",
    "\n",
    "print(\"\\n---- Comparação das Rotações ----\")\n",
    "\n",
    "# test others a's\n",
    "for a_test in slopes_to_test:\n",
    "    #  y = a*x + b_optimo\n",
    "    y_manual_pred = a_test * X.flatten() + b_optimo\n",
    "    \n",
    "    # metrics\n",
    "    # Sum Square Residuals (SSR)\n",
    "    # to plot on graph 2\n",
    "    ssr = np.sum((y - y_manual_pred) ** 2)\n",
    "    r2 = r2_score(y, y_manual_pred)\n",
    "    \n",
    "    ssr_values.append(ssr)\n",
    "    r2_values.append(r2)\n",
    "    slopes_all.append(a_test)\n",
    "    \n",
    "    print(f\"Slope (a): {a_test} | R2: {r2} | SSR (Erro): {ssr}\")\n",
    "    \n",
    "    # plot this line on graph 1\n",
    "    ax1.plot(X, y_manual_pred, linestyle='--', alpha=0.5, label=f'a={a_test}')\n",
    "\n",
    "ax1.set_title(\"Variação da Inclinação (Rotação da Reta)\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ---- Graph 2 ----\n",
    "# specific points\n",
    "ax2.scatter(slopes_to_test, ssr_values, color='gray', s=50, label='Inclinações Testadas')\n",
    "\n",
    "# plot optimal point (Scikit-Learn)\n",
    "ssr_opt = np.sum((y - y_pred_opt) ** 2)\n",
    "ax2.scatter([a_optimo], [ssr_opt], color='red', s=100, zorder=5, label='Mínimo (Scikit-Learn)')\n",
    "ax2.annotate('Melhor \"a\"\\n(Menor Erro)', xy=(a_optimo, ssr_opt), xytext=(a_optimo, ssr_opt + 2),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05), horizontalalignment='center')\n",
    "\n",
    "ax2.set_title(\"Soma dos Quadrados dos Resíduos vs. Inclinação\")\n",
    "ax2.set_xlabel(\"Valor de 'a' (Inclinação)\")\n",
    "ax2.set_ylabel(\"Sum of Squared Residuals (SSR)\")\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e7b104",
   "metadata": {},
   "source": [
    "# Questão G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a53b6c9",
   "metadata": {},
   "source": [
    "## Criando a função para a fatoração de LU com pivoteamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f99703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lu_factoring_with_pivoting(A_in, b_in):\n",
    "    A = A_in.copy().astype(float)\n",
    "    b = b_in.copy().astype(float)\n",
    "    n = len(A)\n",
    "    \n",
    "    # Permutation vector p (p(i) = i)\n",
    "    # start with [0, 1, ..., n-1]\n",
    "    p = np.arange(n) \n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(\"INÍCIO DO PROCESSO (EXEMPLO 7)\")\n",
    "    print(f\"Matriz A(0) Inicial:\\n{A}\")\n",
    "    print(f\"Vetor p inicial: {p + 1}\") # +1 apenas para exibição igual ao livro\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # --- Step 1: Factoring (Calculate factors L e U) ---\n",
    "    # Loop k de 1 até n-1 (no Python: 0 até n-2)\n",
    "    for k in range(n - 1):\n",
    "        print(f\"\\n--- ETAPA {k + 1} ---\")\n",
    "        \n",
    "        # 1. pivot (pv) e pivot position (r)\n",
    "        # find the largest absolute value in column k, line k until n\n",
    "        pv = abs(A[k, k])\n",
    "        r = k\n",
    "        for i in range(k + 1, n):\n",
    "            if abs(A[i, k]) > pv:\n",
    "                pv = abs(A[i, k])\n",
    "                r = i\n",
    "        \n",
    "        print(f\"Pivô escolhido: {A[r, k]} (estava na linha {r+1})\")\n",
    "\n",
    "        # check singularity\n",
    "        if pv == 0:\n",
    "            print(\"A matriz é singular!\")\n",
    "            return None\n",
    "\n",
    "        # 2. permutation (permute lines k and r) if r != k\n",
    "        if r != k:\n",
    "            print(f\"Permutando linhas {k+1} e {r+1}...\")\n",
    "            aux_p = p[k]\n",
    "            p[k] = p[r]\n",
    "            p[r] = aux_p\n",
    "            \n",
    "            # swap matrix A line (entirely line)\n",
    "            row_k = A[k, :].copy()\n",
    "            row_r = A[r, :].copy()\n",
    "            A[k, :] = row_r\n",
    "            A[r, :] = row_k\n",
    "            \n",
    "            print(f\"Vetor p após troca: {p + 1}\")\n",
    "            print(f\"Matriz após troca de linhas:\\n{A}\")\n",
    "        else:\n",
    "            print(\"Nenhuma troca de linha necessária nesta etapa.\")\n",
    "\n",
    "        # 3. Gaussian elimination and multipliers calculate\n",
    "        # for i = k+1 until n\n",
    "        for i in range(k + 1, n):\n",
    "            # calculate multiplier: m = a(i,k)/a(k,k)\n",
    "            m = A[i, k] / A[k, k]\n",
    "            \n",
    "            # store the multiplier in bottom of the matrix (L)\n",
    "            A[i, k] = m \n",
    "            \n",
    "            # Atualiza os elementos restantes da linha: a(i,j) = a(i,j) - m*a(k,j)\n",
    "            # update all line remaining elements\n",
    "            for j in range(k + 1, n):\n",
    "                A[i, j] = A[i, j] - m * A[k, j]\n",
    "\n",
    "        print(f\"\\nMatriz A({k+1}) após eliminação (multiplicadores na parte inferior):\")\n",
    "\n",
    "        # to improve readability\n",
    "        print(np.round(A, 4)) \n",
    "\n",
    "    # --- Finish Factoring ---\n",
    "    \n",
    "    # extrac L and U\n",
    "    L = np.tril(A, -1) + np.eye(n) # Parte [L]ower triangle + identity\n",
    "    U = np.triu(A)                 # Parte [U]pper triangle\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"OS FATORES L e U SÃO:\")\n",
    "    print(\"Matriz L:\")\n",
    "    print(L)\n",
    "    print(\"\\nMatriz U:\")\n",
    "    print(U)\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # --- Step 2: Solve triangular systems ---\n",
    "    \n",
    "    # i) Ly = Pb (onde c = Pb)\n",
    "    # permutation from b vector to obtain c vector\n",
    "    c = np.zeros(n)\n",
    "    print(\"\\nResolvendo Ly = Pb:\")\n",
    "    print(f\"Vetor b original: {b}\")\n",
    "    print(f\"Aplicando permutações p={p+1} em b...\")\n",
    "    for i in range(n):\n",
    "        c[i] = b[p[i]]\n",
    "    print(f\"Vetor Pb (lado direito permutado): {c}\")\n",
    "\n",
    "    # Progressive replacement (Ly = c)\n",
    "    y = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        soma = 0\n",
    "        for j in range(i): # j = 0 until i-1\n",
    "            soma += L[i, j] * y[j]\n",
    "        y[i] = c[i] - soma\n",
    "    \n",
    "    print(f\"Vetor y encontrado: {y}\")\n",
    "\n",
    "    # ii) Ux = y\n",
    "    # Progressive replacement\n",
    "    x = np.zeros(n)\n",
    "    print(\"\\nResolvendo Ux = y:\")\n",
    "    for i in range(n - 1, -1, -1): # i = n-1 until 0 (descending)\n",
    "        soma = 0\n",
    "        for j in range(i + 1, n):\n",
    "            soma += U[i, j] * x[j]\n",
    "        x[i] = (y[i] - soma) / A[i, i] # A[i,i] is the U diagonal element\n",
    "    \n",
    "    print(f\"\\nSOLUÇÃO FINAL (Vetor x):\")\n",
    "    # column vector\n",
    "    print(x.reshape(-1, 1))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e690e2f8",
   "metadata": {},
   "source": [
    "## Resolvendo o exemplo 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb297882",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ex7 = np.array([\n",
    "    [3.0, -4.0, 1.0],\n",
    "    [1.0, 2.0, 2.0],\n",
    "    [4.0, 0.0, -3.0]\n",
    "])\n",
    "\n",
    "b_ex7 = np.array([9.0, 3.0, -2.0])\n",
    "\n",
    "# Rodar a função\n",
    "solution = lu_factoring_with_pivoting(A_ex7, b_ex7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ad8de",
   "metadata": {},
   "source": [
    "# Questão H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1077059",
   "metadata": {},
   "source": [
    "# Questão I"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
